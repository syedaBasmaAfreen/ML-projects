{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOZgw0le5k0aR5Oz+9mOjM+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedaBasmaAfreen/ML-projects/blob/main/fake_news_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dependencies"
      ],
      "metadata": {
        "id": "CZ4wjSvEoyea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "yolW7j7_zsxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "dGI0t2UZzt4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the stopwords in English\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "s3BL1lB2zy26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset to a pandas DataFrame\n",
        "news_dataset = pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "OIw9n6hwz2zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "EKgQmVI6z9Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 5 rows of the dataframe\n",
        "news_dataset.head()"
      ],
      "metadata": {
        "id": "mhUVN1bC0AqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of missing values in the dataset\n",
        "news_dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "FaJL2qUL0JEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# replacing the null values with empty string\n",
        "news_dataset = news_dataset.fillna('')\n"
      ],
      "metadata": {
        "id": "_q-tp5Dx0Nan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging the author name and news title\n",
        "news_dataset['content'] = news_dataset['author']+' '+news_dataset['title']"
      ],
      "metadata": {
        "id": "FquylkXU0NWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_dataset['content'])"
      ],
      "metadata": {
        "id": "khvr1o-o0RS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the data & label\n",
        "X = news_dataset.drop(columns='label', axis=1)\n",
        "Y = news_dataset['label']"
      ],
      "metadata": {
        "id": "7aWcyyVP7sUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "JYfk22Ig8Bai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming:\n",
        "\n",
        "Stemming is the process of reducing a word to its Root word\n",
        "\n",
        "example: actor, actress, acting --> act"
      ],
      "metadata": {
        "id": "nTYCFBj4n6sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem=PorterStemmer()"
      ],
      "metadata": {
        "id": "mqBoO9xImzmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(content):\n",
        "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
        "    stemmed_content = stemmed_content.lower()\n",
        "    stemmed_content = stemmed_content.split()\n",
        "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "    stemmed_content = ' '.join(stemmed_content)\n",
        "    return stemmed_content"
      ],
      "metadata": {
        "id": "A2bHHR-1m8uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset['content']=news_dataset['content'].apply(stemming)"
      ],
      "metadata": {
        "id": "AtyaH7LnnQ8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_dataset['content'])"
      ],
      "metadata": {
        "id": "DZdQzCh_nQ8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " X=news_dataset['content'].values\n",
        " Y=news_dataset['label'].values"
      ],
      "metadata": {
        "id": "PpwsACVBnQ8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n"
      ],
      "metadata": {
        "id": "FTJclwpZnQ8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgkFGXkg6HS4"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu2ZEBkL6QTm"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMfepsQZ6TES"
      },
      "source": [
        "# converting the textual data to numerical data\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(X)\n",
        "\n",
        "X = vectorizer.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJj5esbs7Nzy"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Splitting the dataset to training & test data"
      ],
      "metadata": {
        "id": "3gEC870JoYmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "HIDAxR--r8Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "4UbdgAm6qqN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxDsQvgO8Oln"
      },
      "source": [
        "Training the Model: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrSItcqc7qAy"
      },
      "source": [
        "model = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdVJ839l8Vgx"
      },
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbPKIFT89W1C"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG6gqVty9ZDB"
      },
      "source": [
        "accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgwtWZY59PBw"
      },
      "source": [
        "# accuracy score on the training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L-r5mld-BFn"
      },
      "source": [
        "print('Accuracy score of the training data : ', training_data_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgcn13oO-H6e"
      },
      "source": [
        "# accuracy score on the test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TG0Yof1-vg2"
      },
      "source": [
        "print('Accuracy score of the test data : ', test_data_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yun4seaE-6tV"
      },
      "source": [
        "Making a Predictive System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPjssDL_-zo8"
      },
      "source": [
        "X_new = X_test[3]\n",
        "\n",
        "prediction = model.predict(X_new)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0]==0):\n",
        "  print('The news is Real')\n",
        "else:\n",
        "  print('The news is Fake')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KaWdvDI_eUk"
      },
      "source": [
        "print(Y_test[3])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}